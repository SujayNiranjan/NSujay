
---
layout: default
title: UrbanNav
description: Autonomous Navigation using Multimodal Data
---

# UrbanNav

## **Project Overview**
UrbanNav is a research project that focuses on enabling autonomous robots to navigate urban environments using a combination of sensors like LiDAR, cameras, and GPS. The project involves training navigation models using multimodal data collected by a robot dog.

### **Technologies Used**
- **Hardware**: Unitree Go1 robot dog, Livox LiDAR, Insta360 camera, GPS
- **Software**: NoMaD, GNM, ViNT

### **Key Contributions**
1. Collected multimodal data (images, point clouds, GPS coordinates) for autonomous navigation tasks.
2. Developed models such as **NoMaD** and **GNM** for goal-conditioned navigation.
3. Implemented **ViNT** (Vision-based Transformer) to enhance navigation tasks using visual data.

### **Outcomes**
- Contributed valuable multimodal datasets for training autonomous navigation models.
- Demonstrated successful real-time navigation and obstacle avoidance.

### **Media**
![UrbanNav Robot](urbannav-image1.jpg)  
*Figure: Unitree Go1 robot dog used in UrbanNav.*

![UrbanNav Data Collection](urbannav-image2.jpg)  
*Figure: Collecting multimodal data with LiDAR and cameras.*

[Return to Projects](../../)

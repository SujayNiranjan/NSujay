---
layout: default
title: Projects Overview
description: Portfolio showcasing various robotics projects.
---

<div class="container">
  <div class="projects-header">
    <h1>My Robotics Projects</h1>
    <p>Explore my various robotics and AI projects below. Click on any project to learn more about it.</p>
  </div>

  <!-- Tabs for project navigation -->
  <div class="tabs">
    <button class="tablinks" onclick="openProject(event, 'MappingNYC')">Mapping NYC</button>
    <button class="tablinks" onclick="openProject(event, 'Curb2Door')">Curb2Door</button>
    <button class="tablinks" onclick="openProject(event, 'DiffusionModels')">Diffusion Models</button>
    <button class="tablinks" onclick="openProject(event, 'SwimmerBot')">SwimmerBot</button>
    <button class="tablinks" onclick="openProject(event, 'UrbanNav')">UrbanNav</button>
    <button class="tablinks" onclick="openProject(event, 'BipedRobot')">Biped Robot</button>
  </div>

  <!-- Content for each project -->
  <div id="MappingNYC" class="tabcontent">
    <h2>Mapping NYC</h2>
    <p>MappingNYC is a project aimed at creating accurate 3D maps of New York City using a combination of LiDAR, cameras, and GPS. The goal is to optimize city planning and autonomous navigation systems.</p>
    <p><strong>Technologies Used:</strong> LiDAR, Visual Place Recognition, SLAM, GTSAM, AutoMerge</p>
    <p><strong>Contributions:</strong></p>
    <ul>
      <li>Developed sensor fusion techniques to merge data from LiDAR, cameras, and GPS.</li>
      <li>Implemented Fast-LIO for precise odometry calculations.</li>
      <li>Optimized the use of loop closure techniques to ensure accurate mapping.</li>
    </ul>
    <p><strong>Outcomes:</strong> The project successfully generated scalable 3D maps of NYC and enhanced the accuracy of urban navigation models.</p>
    <img src="mappingnyc-image1.jpg" alt="Mapping NYC in action">
  </div>

  <div id="Curb2Door" class="tabcontent">
    <h2>Curb2Door</h2>
    <p>Curb2Door involves creating detailed 3D maps for urban delivery systems, focusing on curbside and door-to-door routes. The project utilizes advanced sensor fusion techniques to reconstruct city environments and optimize delivery logistics.</p>
    <p><strong>Technologies Used:</strong> Livox LiDAR, Insta360 camera, u-blox GPS, 3D Gaussian Splatting, R3LIVE</p>
    <p><strong>Contributions:</strong></p>
    <ul>
      <li>Developed a mount system integrating LiDAR and cameras for efficient data capture.</li>
      <li>Implemented 3D Gaussian Splatting for efficient point cloud reconstruction.</li>
      <li>Used R3LIVE for real-time 3D reconstruction.</li>
    </ul>
    <p><strong>Outcomes:</strong> Generated highly accurate 3D models of urban areas for delivery optimization and improved mapping techniques for better route planning.</p>
    <img src="curb2door-image1.jpg" alt="Curb2Door system setup">
  </div>

  <div id="DiffusionModels" class="tabcontent">
    <h2>Diffusion Models for Trajectory Prediction</h2>
    <p>This project focuses on predicting a person's future trajectory using diffusion models. By analyzing historical movement data, the system forecasts the likely paths that people will take in future frames.</p>
    <p><strong>Technologies Used:</strong> Diffusion Models, Python, TensorFlow, PyTorch</p>
    <p><strong>Contributions:</strong></p>
    <ul>
      <li>Developed and trained a diffusion model to predict trajectories based on past movements.</li>
      <li>Implemented state-of-the-art machine learning techniques to improve prediction accuracy.</li>
    </ul>
    <p><strong>Outcomes:</strong> Enhanced trajectory prediction models for use in autonomous vehicles and robotics, demonstrating successful predictions in real-world scenarios.</p>
    <img src="diffusion-image1.jpg" alt="Trajectory Prediction with Diffusion Models">
  </div>

  <div id="SwimmerBot" class="tabcontent">
    <h2>SwimmerBot</h2>
    <p>SwimmerBot is a robot designed to autonomously track swimmers in a pool, following them while filming underwater. The project focuses on creating a robust tracking system using computer vision and sensor fusion.</p>
    <p><strong>Technologies Used:</strong> Custom-built robot, GPS, IMU, OpenCV, ROS</p>
    <p><strong>Contributions:</strong></p>
    <ul>
      <li>Developed an autonomous tracking system to follow swimmers across the pool.</li>
      <li>Integrated sensors (GPS, IMU) for accurate positioning and movement tracking.</li>
      <li>Implemented computer vision algorithms to ensure accurate tracking of swimmers.</li>
    </ul>
    <p><strong>Outcomes:</strong> A fully autonomous system capable of tracking and filming swimmers for training and analysis purposes.</p>
    <img src="swimmerbot-image1.jpg" alt="SwimmerBot tracking swimmers">
  </div>

  <div id="UrbanNav" class="tabcontent">
    <h2>UrbanNav</h2>
    <p>UrbanNav is a research project that focuses on enabling autonomous robots to navigate urban environments using a combination of sensors like LiDAR, cameras, and GPS. The project involves training navigation models using multimodal data collected by a robot dog.</p>
    <p><strong>Technologies Used:</strong> Unitree Go1 robot dog, Livox LiDAR, Insta360 camera, GPS, NoMaD, GNM, ViNT</p>
    <p><strong>Contributions:</strong></p>
    <ul>
      <li>Collected multimodal data (images, point clouds, GPS coordinates) for autonomous navigation tasks.</li>
      <li>Developed models such as NoMaD and GNM for goal-conditioned navigation.</li>
      <li>Implemented ViNT (Vision-based Transformer) to enhance navigation tasks using visual data.</li>
    </ul>
    <p><strong>Outcomes:</strong> Contributed valuable multimodal datasets for training autonomous navigation models and demonstrated successful real-time navigation and obstacle avoidance.</p>
    <img src="urbannav-image1.jpg" alt="UrbanNav robot in action">
  </div>

  <div id="BipedRobot" class="tabcontent">
    <h2>Biped Robot Development</h2>
    <p>This project involved designing a biped robot with eight degrees of freedom, integrating motor control and sensory feedback to enhance movement and gait stability.</p>
    <p><strong>Technologies Used:</strong> Custom-built biped robot, IMU sensors, motors, MATLAB, ROS</p>
    <p><strong>Contributions:</strong></p>
    <ul>
      <li>Designed and built a biped robot capable of walking and maintaining balance.</li>
      <li>Integrated sensory feedback using IMU sensors to optimize movement.</li>
      <li>Developed control algorithms for smooth and stable gait.</li>
    </ul>
    <p><strong>Outcomes:</strong> Successfully created a biped robot capable of walking with improved gait stability, contributing to the field of bipedal locomotion in robotics.</p>
    <img src="biped-image1.jpg" alt="Biped Robot development and testing">
  </div>
</div>

<!-- Footer -->
<footer>
  <p>&copy; 2024 Niranjan Sujay | All rights reserved.</p>
</footer>

<script>
  function openProject(evt, projectName) {
    var i, tabcontent, tablinks;
    tabcontent = document.getElementsByClassName("tabcontent");
    for (i = 0; i < tabcontent.length; i++) {
      tabcontent[i].style.display = "none";
    }
    tablinks = document.getElementsByClassName("tablinks");
    for (i = 0; i < tablinks.length; i++) {
      tablinks[i].className = tablinks[i].className.replace(" active", "");
    }
    document.getElementById(projectName).style.display = "block";
    evt.currentTarget.className += " active";
  }

  // Default display project
  document.getElementsByClassName("tablinks")[0].click();
</script>

<style>
  .tabcontent {
    display: none;
    padding: 20px;
    background-color: #1a1a1a;
    color: white;
    margin-top: 10px;
  }

  .tabs {
    display: flex;
    justify-content: space-evenly;
    margin-top: 20px;
  }

  .tablinks {
    background-color: #333;
    color: white;
    padding: 14px 20px;
    cursor: pointer;
    border: none;
    font-size: 16px;
  }

  .tablinks:hover {
    background-color: #555;
  }

  .tablinks.active {
    background-color: #444;
  }

  footer {
    text-align: center;
    padding: 20px;
    background-color: #333;
    color: white;
  }
</style>
